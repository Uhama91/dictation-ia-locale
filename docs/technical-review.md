# Revue Technique Comparative ‚Äî Dictation IA Locale

**Date :** 2026-02-24
**Sources :** Recherche web approfondie (20+ sources, arXiv, GitHub, benchmarks 2025-2026)

---

## Verdict global

La tech spec actuelle (Rust + Tauri, Whisper GGML, LLM < 2B, Silero VAD) est **solide mais sous-optimale** sur plusieurs axes. Des alternatives concr√®tes existent sur chaque composant, avec des gains de latence significatifs accessibles.

---

## 1. Risques techniques majeurs

### üî¥ Risque #1 ‚Äî Fine-tuning LLM (risque le plus √©lev√©)
- Construire 5-10k paires FR de qualit√© demande √©norm√©ment de travail manuel ou une g√©n√©ration synth√©tique √† valider
- Le zero-edit rate > 70% **d√©pend enti√®rement de la qualit√© du dataset** ‚Äî c'est le point le plus incertain
- **Mitigation** : utiliser Common Voice FR + MLS FR + g√©n√©ration synth√©tique (voir section 5)

### üî¥ Risque #2 ‚Äî Latence cible ambitieuse
- < 2s avec deux mod√®les d'inf√©rence s√©quentiels (Whisper ‚Üí LLM) sur machines 6-8 Go RAM est **tr√®s ambitieux**
- Wispr Flow atteint < 700ms avec TensorRT-LLM sur GPU cloud ‚Äî **incomparable avec llama.cpp local**
- **Mitigation** : WhisperKit CoreML + Qwen2.5-0.5B Q4 peuvent atteindre 650-850ms sur M2/M3

### üü° Risque #3 ‚Äî D√©pendance √† transcribe-rs
- `transcribe-rs` est une crate non officielle qui unifie plusieurs moteurs STT mais ajoute une couche d'abstraction
- Moins de contr√¥le sur les optimisations CoreML/Metal sp√©cifiques √† macOS
- **Mitigation** : utiliser whisper.cpp directement via FFI Rust pour acc√®s aux optimisations CoreML encoder

### üü° Risque #4 ‚Äî Menu bar macOS via Tauri
- Tauri offre un contr√¥le minimal sur le comportement natif de la menu bar macOS
- Les interactions se sentent "dat√©es" compar√©es aux apps natives (retour terrain 2025)
- **Mitigation** : plugin Swift pour la menu bar (voir section 4)

---

## 2. STT ‚Äî Meilleures alternatives pour le fran√ßais

### Recommandation principale : Whisper large-v3-turbo Q5_0

| Mod√®le | Latence (Apple Silicon) | RAM | Pr√©cision FR |
|--------|------------------------|-----|--------------|
| Whisper small Q5 (actuel) | ~400ms | ~460 Mo | Bonne |
| Whisper medium Q4 (actuel) | ~600ms | ~492 Mo | Tr√®s bonne |
| **Whisper large-v3-turbo Q5_0** | **~600-800ms** | **~800 Mo** | **Excellente** |
| **WhisperKit CoreML (ANE)** | **~450ms** | **~800 Mo** | **Excellente** |

**Whisper large-v3-turbo** = d√©codeur r√©duit de 32 ‚Üí 4 couches (5.4x plus rapide que large-v3), pr√©cision quasi identique au fran√ßais. WER fran√ßais : 3-8% sur donn√©es propres.

**Optimisation cruciale** : utiliser whisper.cpp compil√© avec `WHISPER_COREML=1` :
- Encoder sur Apple Neural Engine (ANE) : **3x plus rapide**
- D√©codeur sur Metal GPU : **3-4x plus rapide**
- Combinaison CoreML encoder + Metal decoder ‚Üí latence ~450-600ms vs ~1.5s sans

```bash
# Compilation whisper.cpp avec CoreML
cmake -B build -DWHISPER_COREML=1 -DWHISPER_METAL=1
```

### Alternatives √† consid√©rer

- **WhisperKit (Swift/CoreML)** : latence 0.45s sur M3 Max, mais n√©cessite Swift (voir section 4)
- **Moonshine** : ne supporte pas le fran√ßais ‚Äî √† √©liminer
- **Parakeet NVIDIA** : anglais uniquement pour les performances optimales ‚Äî √† √©liminer
- **MMS / Wav2Vec2 FR** : d√©pass√©s par Whisper large-v3 ‚Äî √† √©liminer

---

## 3. LLM de nettoyage ‚Äî Taille optimale

### Un LLM < 1B params peut suffire ‚úÖ

**Recommandation : Qwen2.5-0.5B-Instruct Q4**
- Taille : ~300 Mo RAM (vs ~1.2 Go pour 1.5B)
- Supporte officiellement le fran√ßais (29 langues)
- Suffisant pour une t√¢che contrainte (correction, non g√©n√©ration libre)
- Fine-tuning QLoRA support√© officiellement

**Comparatif mod√®les < 2B :**

| Mod√®le | RAM (Q4) | FR natif | Recommandation |
|--------|----------|----------|----------------|
| **Qwen2.5-0.5B Q4** | ~300 Mo | ‚úÖ Oui | ‚≠ê Premier choix |
| Qwen2.5-1.5B Q4 | ~900 Mo | ‚úÖ Oui | Fallback si 0.5B insuffisant |
| SmolLM2-135M | ~100 Mo | ‚ùå Faible | Insuffisant seul pour FR |
| SmolLM2-360M | ~230 Mo | ‚ùå Faible | Insuffisant seul pour FR |
| Phi-3.5-mini (3.8B) | ~2.2 Go | ‚úÖ Bien | Trop lourd pour le budget |

### Approche hybride recommand√©e (meilleur ratio qualit√©/latence)

```
Transcription brute
    ‚Üì
[R√®gles rapides < 1ms]
  - Filler words FR (euh, heu, bah, ben, du coup, genre, voil√†)
  - B√©gaiements
  - Ponctuation basique (majuscule d√©but, point final)
    ‚Üì
Score de confiance Whisper √©lev√© ? ‚Üí Coller directement (no LLM)
Score bas ou phrases longues ? ‚Üí Qwen2.5-0.5B Q4 (nettoyage complet)
```

**R√©sultat attendu** : 60-65% des cas trait√©s sans LLM (< 5ms), LLM uniquement pour les 35-40% restants (~150-200ms).

---

## 4. Architecture ‚Äî Swift vs Rust + Tauri

### Recommandation : Architecture hybride Rust + plugin Swift

Ne pas abandonner Handy/Rust, mais ajouter une couche Swift pour les composants macOS critiques.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Tauri 2.x (Web frontend ‚Äî UI settings l√©g√®re)  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Rust backend (orchestration + LLM)              ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ VAD (Silero via ONNX / vad-rs)              ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ LLM cleanup (Qwen2.5-0.5B via llama-cpp-rs) ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ Pipeline orchestration (async channels)    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Plugin Swift (FFI depuis Rust) ‚Äî composants cl√©s‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ WhisperKit (CoreML + ANE) ‚Äî STT ultra-rapide‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Accessibility API (paste au curseur natif)  ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Global hotkeys (CGEvent/Carbon)             ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ Menu bar native (NSStatusBar)               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Pourquoi pas Swift pur ?**
- Abandonner Handy = tout r√©√©crire
- Rust reste meilleur pour le pipeline bas niveau (VAD, buffers audio, async)
- llama-cpp-rs est mature pour Rust

**Pourquoi ajouter Swift ?**
- WhisperKit ANE : 3-5x plus rapide que GGML Metal seul
- Menu bar macOS native = exp√©rience utilisateur correcte
- Accessibility API sans bridge complexe

---

## 5. Optimisation de la latence

### Projection avec stack optimis√©e

```
Raccourci press√©
    ‚Üì
Capture audio (M1/M2/M3 ‚Äî AVFoundation ou cpal)
    ‚Üì
TEN VAD (latence r√©duite vs Silero) d√©tecte fin de parole    ~50ms
    ‚Üì
Whisper large-v3-turbo Q5_0
  - Encoder CoreML/ANE                                       ~150ms
  - D√©codeur Metal                                           ~300ms
  Total STT                                                  ~450-600ms
    ‚Üì
Qwen2.5-0.5B Q4 (si n√©cessaire)                             ~150-200ms
    ‚Üì
Paste au curseur (Accessibility API natif)                   ~10ms

TOTAL ESTIM√â (M2/M3)                                        ~650-860ms
TOTAL ESTIM√â (M1)                                           ~1.0-1.4s
```

### VAD ‚Äî Upgrade recommand√© : TEN VAD

**TEN VAD** (GitHub: TEN-framework) pr√©sente une latence switch speech‚Üísilence significativement r√©duite par rapport √† Silero v4. Benchmark 2025 (Picovoice) : TEN VAD est dans le top 3 des VAD pour la d√©tection de fin de parole. Gain : -100 √† -200ms sur la d√©tection de fin d'enregistrement.

### Pipeline asynchrone STT + LLM (Phase 2)

Gain th√©orique de 200-400ms en faisant commencer le LLM sur les premiers tokens STT :

```
[STT d√©marre] ‚Üí [tokens partiels √† 0.5s] ‚Üí [LLM commence sur partiel]
               ‚Üí [STT finit √† 0.8s] ‚Üí [LLM compl√®te le delta]
Total avec overlap : ~700-900ms (vs ~1.1s s√©quentiel)
```

√Ä impl√©menter en Phase 2 apr√®s validation du pipeline de base.

---

## 6. Dataset fine-tuning FR

### Sources de donn√©es disponibles

| Source | Volume | Type | Qualit√© |
|--------|--------|------|---------|
| **Mozilla Common Voice FR v18+** | 1 200h valid√©es | Lectures + corrections humaines | ‚≠ê‚≠ê‚≠ê |
| **MLS (Multilingual LibriSpeech) FR** | ~1 100h | Livres audio + textes align√©s | ‚≠ê‚≠ê‚≠ê |
| **ESLO / TCOF (ORTOLANG/CNRS)** | ~200h | Fran√ßais parl√© spontan√© | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **G√©n√©ration synth√©tique LLM** | Illimit√©e | Simul√©e | ‚≠ê‚≠ê |

### Architecture dataset recommand√©e (10k paires)

```
10k paires total :
‚îú‚îÄ‚îÄ 3k : Common Voice FR ‚Üí Whisper small (brut) / transcription humaine (propre)
‚îú‚îÄ‚îÄ 3k : MLS FR (m√™me m√©thode)
‚îú‚îÄ‚îÄ 2k : ESLO/TCOF (fran√ßais spontan√©, le plus difficile)
‚îî‚îÄ‚îÄ 2k : Synth√©tique LLM (augmentation, cas difficiles : homophones FR, liaisons)

Homophones FR √† couvrir : ces/ses/c'est, √†/a, ou/o√π, et/est, on/ont, son/sont
```

### M√©thode g√©n√©ration synth√©tique

1. Partir de texte FR propre (Wikipedia, news)
2. Simuler erreurs STT via LLM : supprimer ponctuation, ajouter erreurs homophoniques FR
3. Qualit√© attendue : 70-80% des donn√©es r√©elles pour cette t√¢che contrainte

---

## Synth√®se des recommandations prioritaires

| Composant | Actuel | Recommand√© | Impact |
|-----------|--------|-----------|--------|
| **STT mod√®le** | Whisper small/medium Q4 | Whisper large-v3-turbo Q5_0 | +15-20% pr√©cision FR |
| **STT runtime** | transcribe-rs GGML | whisper.cpp CoreML encoder + Metal | 3-5x vitesse encoder |
| **VAD** | Silero v4 | TEN VAD | -100-200ms fin de phrase |
| **LLM cleanup** | Qwen2.5-1.5B ou SmolLM2-1.7B | **Qwen2.5-0.5B Q4 + r√®gles hybrides** | -50% RAM, latence similaire |
| **Framework** | Rust + Tauri seul | Rust + Tauri + **plugin Swift** | Acc√®s ANE + menu bar native |
| **Pipeline** | S√©quentiel | Async STT‚ÜíLLM overlap (Ph. 2) | -200-400ms latence |

---

## Sources

- [mac-whisper-speedtest benchmarks](https://github.com/anvanvan/mac-whisper-speedtest)
- [WhisperKit On-device Real-time ASR ‚Äî arXiv 2507.10860](https://arxiv.org/html/2507.10860v1)
- [Whisper large-v3-turbo ‚Äî Whisper Notes Blog](https://whispernotes.app/blog/introducing-whisper-large-v3-turbo)
- [Best open source STT 2026 ‚Äî Northflank benchmarks](https://northflank.com/blog/best-open-source-speech-to-text-stt-model-in-2026-benchmarks)
- [Parakeet v3 NVIDIA ‚Äî Caasify](https://caasify.com/blog/parakeet-v3-nvidias-asr-model-competing-with-whisper/)
- [TEN VAD low-latency ‚Äî GitHub](https://github.com/TEN-framework/ten-vad)
- [Best VAD 2025 ‚Äî Picovoice](https://picovoice.ai/blog/best-voice-activity-detection-vad-2025/)
- [whisper.cpp CoreML 3x speedup ‚Äî HN](https://news.ycombinator.com/item?id=43880345)
- [WhisperKit ‚Äî GitHub argmaxinc](https://github.com/argmaxinc/WhisperKit)
- [Tauri macOS menu bar limites](https://github.com/tauri-apps/tauri/discussions/6223)
- [candle-coreml Rust ANE bindings](https://crates.io/crates/candle-coreml)
- [Bloomberg Streaming Whisper Interspeech 2025](https://www.bloomberg.com/company/stories/bloombergs-ai-researchers-turn-whisper-into-a-true-streaming-asr-model-at-interspeech-2025/)
- [Concurrent voice AI pipelines ‚Äî Gladia](https://www.gladia.io/blog/concurrent-pipelines-for-voice-ai)
- [SmolLM2 ‚Äî arXiv 2502.02737](https://arxiv.org/html/2502.02737v1)
- [Qwen2.5-1.5B-Instruct ‚Äî Hugging Face](https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct)
